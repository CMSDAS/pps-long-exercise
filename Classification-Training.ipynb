{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a multivariate discrimination\n",
    "\n",
    "Below we prepare a simple setup to train a multivariate discriminator to separate the signal from the background.\n",
    "It's meant just an appetizer for you to explore. After you go through it it may be a good occasion to put in practice what you learned in the short exercise about Machine Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user mplhep #uncomment if loading of mplhep fails\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global configurarables (check the Data-Inspection notebook for consistency)\n",
    "proton_selection = \"MultiRP\"\n",
    "PATH='/eos/user/c/cmsdas/short-exercises/pps-protons-tutorial/data'\n",
    "\n",
    "#eras=['B','C1','D','F1'] #uncomment to use all data\n",
    "eras=['B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the data and simulation\n",
    "\n",
    "The following cell is used to load the training data to memory. Further pre-selection will be applied below.\n",
    "\n",
    "The data which we are going to use to model the background has been pre-processed with an event mixing technique.\n",
    "For each event the reconstructed protons have been substituted with protons from another event,\n",
    "guaranteeing that there is no correlation between the central event and the one reconstucted in the PPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GetData(flist,chunk_size=None):\n",
    "    \n",
    "    \"\"\" \n",
    "    opens a summary file or list of summary files and convert them to a pandas dataframe \n",
    "    if given the chunk_size will be used to collect events in chunks of this size\n",
    "    \"\"\"\n",
    "    \n",
    "    flist=flist if isinstance(flist,list) else [flist]\n",
    "    \n",
    "    df,df_counts=[],[]\n",
    "    \n",
    "    for filename in flist:\n",
    "    \n",
    "        with h5py.File(filename, 'r') as f:\n",
    "\n",
    "            print('Collecting data from',filename)\n",
    "            \n",
    "            dset            = f['protons']\n",
    "            dset_columns    = f['columns']\n",
    "            dset_selections = f['selections']\n",
    "            dset_counts     = f['event_counts']\n",
    "            \n",
    "            #read the data\n",
    "            columns = list( dset_columns )\n",
    "            columns_str = [ item.decode(\"utf-8\") for item in columns ]\n",
    "            if chunk_size is None:\n",
    "                start=[0]\n",
    "                stop=[dset.shape[0]]\n",
    "            else:\n",
    "                entries = dset.shape[0]\n",
    "                start = list( range( 0, entries, chunk_size ) )\n",
    "                stop = start[1:] + [entries]\n",
    "                \n",
    "            for idx in range( len( start) ):\n",
    "                print('\\tCollecting events',start[idx], stop[idx] )\n",
    "\n",
    "                df.append( pd.DataFrame( dset[start[idx]:stop[idx]], \n",
    "                                         columns=columns_str ) )\n",
    "                df[-1]=df[-1][['Run', 'LumiSection', 'EventNum', 'CrossingAngle', \n",
    "                               'MultiRP', 'Arm', 'RPId1', 'RPId2', 'TrackX1', 'TrackY1', 'TrackX2', 'TrackY2',\n",
    "                               'Xi', 'T', 'ThX', 'ThY', 'Time',\n",
    "                               'Muon0Pt', 'Muon1Pt', 'InvMass', 'ExtraPfCands', 'Acopl', 'XiMuMuPlus', 'XiMuMuMinus'] ].astype( { \"Run\": \"int64\", \"LumiSection\": \"int64\", \"EventNum\": \"int64\", \"MultiRP\": \"int32\", \"Arm\": \"int32\", \"RPId1\": \"int32\", \"RPId2\": \"int32\", \"ExtraPfCands\": \"int32\" } )\n",
    "              \n",
    "            #read the selection counters\n",
    "            selections = list( dset_selections )\n",
    "            selections_str = [ item.decode(\"utf-8\") for item in selections ]        \n",
    "            df_counts.append( pd.Series( list( dset_counts ), index=selections_str ) )\n",
    "    \n",
    "    n=len( df ) \n",
    "    print('\\tReturning the result of %d merged datasets'%n)\n",
    "    df_final=pd.concat(df)\n",
    "    \n",
    "    #merge the counts\n",
    "    df_counts_final = df_counts[0]\n",
    "    for idx in range( 1, len(df_counts) ):\n",
    "        df_counts_final = df_counts_final.add( df_counts[idx] )\n",
    "\n",
    "    #merge the data\n",
    "    \n",
    "    \n",
    "    return df_final,df_counts_final\n",
    "    \n",
    "print('[Signal simulation]')\n",
    "df_signal,df_counts_signal = GetData(PATH+'/output-MC2017-Elastic-Non3+3-PreSel.h5')\n",
    "print('Selection counts')\n",
    "print(df_counts_signal)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('[Data (to be used as background)]')\n",
    "data_files = [PATH+'/output-UL2017{}-PreSel-Rnd-Res20.h5'.format(era) for era in eras]\n",
    "df_bkg,df_counts_bkg = GetData(data_files,chunk_size=1000000)\n",
    "print('Selection counts')\n",
    "print(df_counts_bkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "We apply the following selection to the signal and data\n",
    "\n",
    "* require $m_{ll}>110$ GeV\n",
    "* set the dilepton xi according to the arm where a proton was reconstructed \n",
    "* use the proton reconstruction algorithm as required at the start of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareData(df):\n",
    "    \n",
    "    \"\"\"applies baseline selection cuts\"\"\"\n",
    "\n",
    "    msk = ( df[\"InvMass\"] >= 110. )\n",
    "\n",
    "    msk1 = None\n",
    "    msk2 = None\n",
    "    if proton_selection == \"SingleRP\":\n",
    "        # Single-RP in pixel stations\n",
    "        msk1_arm = ( df[\"RPId1\"] == 23 )\n",
    "        msk2_arm = ( df[\"RPId1\"] == 123 )\n",
    "        multiRP=0\n",
    "    elif proton_selection == \"MultiRP\":\n",
    "        # Multi-RP\n",
    "        msk1_arm = ( df[\"Arm\"] == 0 )\n",
    "        msk2_arm = ( df[\"Arm\"] == 1 )\n",
    "        multiRP=1\n",
    "   \n",
    "    df[ \"XiMuMu\" ] = np.nan\n",
    "    df[ \"XiMuMu\" ].where( ~msk1_arm, df[ \"XiMuMuPlus\" ],  inplace=True )\n",
    "    df[ \"XiMuMu\" ].where( ~msk2_arm, df[ \"XiMuMuMinus\" ], inplace=True )\n",
    "    msk1 = msk & ( df[\"MultiRP\"] == multiRP) & msk1_arm\n",
    "    msk2 = msk & ( df[\"MultiRP\"] == multiRP) & msk2_arm\n",
    "   \n",
    "    return df[msk1 | msk2].copy()\n",
    "\n",
    "df_signal_prep = PrepareData(df_signal)\n",
    "df_bkg_prep    = PrepareData(df_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Signal prepared',df_signal_prep.shape)\n",
    "\n",
    "train_vars=['Muon0Pt', 'Muon1Pt', 'InvMass',   'XiMuMu', 'Xi', 'Acopl','ExtraPfCands']\n",
    "\n",
    "#draw the correlation matrix for the training variables\n",
    "print(train_vars)\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "plt.matshow(df_signal_prep[train_vars].corr(), fignum=fig.number)\n",
    "cb = plt.colorbar()\n",
    "plt.clim(-1,1)\n",
    "plt.title('Signal correlation Matrix', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "df_signal_prep[train_vars].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Background prepared',df_bkg_prep.shape)\n",
    "\n",
    "#draw the correlation matrix for these variables\n",
    "print(train_vars)\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "plt.matshow(df_bkg_prep[train_vars].corr(), fignum=fig.number)\n",
    "cb = plt.colorbar()\n",
    "plt.clim(-1,1)\n",
    "plt.title('Background correlation Matrix', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "df_bkg_prep[train_vars].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "\n",
    "Having the data prepared we now turn to building a simple model using the same training variables inspected above.\n",
    "`sklearn` is used to define the training and test sample and to train a model which will do binary classification (0=background, 1=signal).\n",
    "The model is based on a [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/tree.html#tree).\n",
    "The [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) is then used to improve the base training of the DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sig=df_signal_prep[train_vars].copy()\n",
    "X_bkg=df_bkg_prep[train_vars].copy()\n",
    "\n",
    "y_sig = np.ones( len(X_sig) )\n",
    "y_bkg = np.zeros( len(X_bkg) )\n",
    "\n",
    "X = pd.concat( [X_sig, X_bkg] ) \n",
    "y = np.concatenate( [y_sig, y_bkg] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide into training an testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, shuffle=True, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#fit the parameters of the DecisionTreeClassifier\n",
    "ada_clf = AdaBoostClassifier( DecisionTreeClassifier( max_depth=4 ),\n",
    "                              n_estimators = 200,\n",
    "                              algorithm=\"SAMME.R\",\n",
    "                              learning_rate = 0.5)\n",
    "ada_clf.fit( X_train, y_train )\n",
    "clf = ada_clf\n",
    "print ( clf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "from joblib import dump, load\n",
    "dump(clf, 'pps_longexercise_clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection of the training result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy of the predictions and the receiver-operating characteristic (ROC) curve. \n",
    "We use several function from sklearn to do this. \n",
    "In case you are not acquainted with them check the following links:\n",
    "* [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) -  returns the fraction of correctly classified samples\n",
    "* [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) - used to compute the ROC curve for a binary classification\n",
    "* [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) - computes the area under the ROC\n",
    "You'll see that the result is extremely accurate and has a large background rejection power.\n",
    "\n",
    "**TASK 1**\n",
    "\n",
    "Can you identify which variables contribute mostly to this? (Hint: check for correlations with the classifier, re-train with N-1 variables are some possibilities.\n",
    "Evaluating the impact via [permutation feature importance](https://scikit-learn.org/stable/modules/permutation_importance.html), will give you already a good hint.\n",
    "If you are really into it try out a more complex (but also more correct) evaluation in this [example](https://colab.research.google.com/github/GilesStrong/lumin/blob/v0.5.1/examples/Feature_Selection.ipynb) using the [lumin](https://github.com/GilesStrong/lumin) package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test_pred = clf.predict( X_test )\n",
    "print('Accuracy on the test dataset is:',accuracy_score( y_test, y_test_pred ))\n",
    "\n",
    "y_sig_pred = clf.predict( X_sig )\n",
    "y_bkg_pred = clf.predict( X_bkg )\n",
    "print ('Accuracy on the full signal data is', accuracy_score( y_sig, y_sig_pred ) )\n",
    "print ('Accuracy on the full background data is', accuracy_score( y_bkg, y_bkg_pred ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#get the probability for the event to be signal\n",
    "y_test_proba = clf.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_test_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "fig= plt.figure( figsize=(6,6) )\n",
    "plt.plot(tpr,1/fpr,label=\"ROC AUC={:.3f}\".format(auc))\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Background rejection (1/false positive rate)')\n",
    "plt.xlabel('Signal efficiency (true positive rate)')\n",
    "plt.xlim(0.88,1.0)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the discriminator shape. The distributions for the signal and background are characterized by a clear separation.\n",
    "\n",
    "**TASK 2**\n",
    "\n",
    "Can you make an analogous distribution, but for the probability for an event to be background? \n",
    "What is the relation between the two?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(8,8) )\n",
    "\n",
    "bins=np.linspace(0.,1.,50)\n",
    "plt.hist( y_test_proba[y_test == 0],  color='lightgray', bins=bins, label='Background')\n",
    "plt.hist( y_test_proba[y_test == 1],  histtype='step',   bins=bins, label='Signal', linewidth=2 )\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Events (a.u)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot2D(x,y,data_sig,data_bkg,msk_sig,msk_bkg,xran=[0.,0.15],yran=[0.,0.15]):\n",
    " \n",
    "    \"\"\"a simple routine to plot the signal and background components\"\"\"\n",
    "\n",
    "    fig= plt.figure( figsize=(10,10) )\n",
    "    plt.plot( data_bkg[x][ msk_bkg ], data_bkg[y][ msk_bkg ], 'ro', label='Background' )\n",
    "    plt.plot( data_sig[x][ msk_sig ], data_sig[y][ msk_sig ], 'bo', label='Signal' )\n",
    "    \n",
    "    if 'Xi' in x and 'Xi' in y:\n",
    "        plt.plot( xran,yran, 'k--', linewidth=1 )\n",
    "        plt.plot( xran, [j*0.90 for j in yran], 'k:', linewidth=1 )\n",
    "        plt.plot( xran, [j*1.10 for j in yran], 'k:', linewidth=1 )\n",
    "\n",
    "    plt.xlim(*xran)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylim(*yran)\n",
    "    plt.ylabel(y)\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset: the events classified as signal correlate more strongly in the reconstucted $\\xi$ plane. You can compare the result to the one obtained in the Data-Inspection notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_bkg = ( y_test_pred == 0 )\n",
    "msk_sig = ( y_test_pred == 1 )\n",
    "Plot2D('Xi','XiMuMu',X_test,X_test,msk_sig,msk_bkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the correlations in the $\\xi$ per PPS arm.\n",
    "Check where the correct predictions in the signal and background datasets lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_bkg_1 = None\n",
    "msk_bkg_2 = None\n",
    "msk_sig_1 = None\n",
    "msk_sig_2 = None\n",
    "if proton_selection == \"SingleRP\":\n",
    "    msk_bkg_1 = ( df_bkg_prep[ \"RPId1\" ] == 23 ) & ( y_bkg_pred == 0 )\n",
    "    msk_bkg_2 = ( df_bkg_prep[ \"RPId1\" ] == 123 ) & ( y_bkg_pred == 0 )\n",
    "    msk_sig_1 = ( df_signal_prep[ \"RPId1\" ] == 23 ) & ( y_sig_pred == 1 )\n",
    "    msk_sig_2 = ( df_signal_prep[ \"RPId1\" ] == 123 ) & ( y_sig_pred == 1 )\n",
    "elif proton_selection == \"MultiRP\":\n",
    "    msk_bkg_1 = ( df_bkg_prep[ \"Arm\" ] == 0 ) & ( y_bkg_pred == 0 )\n",
    "    msk_bkg_2 = ( df_bkg_prep[ \"Arm\" ] == 1 ) & ( y_bkg_pred == 0 )\n",
    "    msk_sig_1 = ( df_signal_prep[ \"Arm\" ] == 0 ) & ( y_sig_pred == 1 )\n",
    "    msk_sig_2 = ( df_signal_prep[ \"Arm\" ] == 1 ) & ( y_sig_pred == 1 )\n",
    "Plot2D('Xi','XiMuMuPlus',df_signal_prep,df_bkg_prep,msk_sig_1,msk_bkg_1)\n",
    "Plot2D('Xi','XiMuMuMinus',df_signal_prep,df_bkg_prep,msk_sig_2,msk_bkg_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogous to the previous set of plots but now we plot the background events which have been wrongly assigned as signal by the predictor.\n",
    "False positive rate events are a handful events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_bkgerr_1 = None\n",
    "msk_bkgerr_2 = None\n",
    "if proton_selection == \"SingleRP\":\n",
    "    msk_bkgerr_1 = ( df_bkg_prep[ \"RPId1\" ] == 23 ) & ( y_bkg_pred == 1 )\n",
    "    msk_bkgerr_2 = ( df_bkg_prep[ \"RPId1\" ] == 123 ) & ( y_bkg_pred == 1 )\n",
    "elif proton_selection == \"MultiRP\":\n",
    "    msk_bkgerr_1 = ( df_bkg_prep[ \"Arm\" ] == 0 ) & ( y_bkg_pred == 1 )\n",
    "    msk_bkgerr_2 = ( df_bkg_prep[ \"Arm\" ] == 1 ) & ( y_bkg_pred == 1 )\n",
    "Plot2D('Xi','XiMuMuPlus', df_bkg_prep,df_bkg_prep, msk_bkgerr_1, msk_bkg_1)\n",
    "Plot2D('Xi','XiMuMuMinus',df_bkg_prep,df_bkg_prep, msk_bkgerr_2, msk_bkg_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the same distributions but now using events where the signal was misassigned as background.\n",
    "Also an handful of events is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_sigerr_1 = None\n",
    "msk_sigerr_2 = None\n",
    "if proton_selection == \"SingleRP\":\n",
    "    msk_sigerr_1 = ( df_signal_prep[ \"RPId1\" ] == 23 ) & ( y_sig_pred == 0 )\n",
    "    msk_sigerr_2 = ( df_signal_prep[ \"RPId1\" ] == 123 ) & ( y_sig_pred == 0 )\n",
    "elif proton_selection == \"MultiRP\":\n",
    "    msk_sigerr_1 = ( df_signal_prep[ \"Arm\" ] == 0 ) & ( y_sig_pred == 0 )\n",
    "    msk_sigerr_2 = ( df_signal_prep[ \"Arm\" ] == 1 ) & ( y_sig_pred == 0 )\n",
    "Plot2D('Xi','XiMuMuPlus', df_signal_prep,df_signal_prep, msk_sigerr_1, msk_sig_1)\n",
    "Plot2D('Xi','XiMuMuMinus',df_signal_prep,df_signal_prep, msk_sigerr_2, msk_sig_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the training variable distributions for events classified as signal or background in the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showDist(x,data,mask_sig, mask_bkg,nbins):\n",
    "    \n",
    "    \"\"\"a simple function to compare signal-like and background-like\"\"\"\n",
    "    \n",
    "    fig = plt.figure( figsize=(6,6) )\n",
    "    _,bins=np.histogram(data[x],bins=nbins)\n",
    "    plt.hist( data[ x ][ mask_bkg ], color='lightgray', bins=bins, density=True, label='Background' )\n",
    "    plt.hist( data[ x ][ mask_sig ], histtype='step',   bins=bins, density=True, label='Signal', linewidth=2)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel('Events (a.u.)')\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "for x in train_vars:\n",
    "    showDist(x,X_test,(y_test_pred==1),(y_test_pred==0),50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the data using the trained classifier\n",
    "\n",
    "We now read, prepare and run the prediction for the data. \n",
    "The classifier output is used to further select the data and inspect some distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "print('\\n')\n",
    "print('[Data]')\n",
    "data_files = [PATH+'/output-UL2017{}-PreSel.h5'.format(era) for era in eras]\n",
    "df_data,df_counts_data = GetData(data_files,chunk_size=1000000)\n",
    "print('Selection counts')\n",
    "print(df_counts_data)\n",
    "\n",
    "#prepare the data\n",
    "df_data_prep=PrepareData(df_data)\n",
    "\n",
    "\n",
    "#run the prediction\n",
    "df_data_prep['clf_category'] = clf.predict( df_data_prep[train_vars] ).astype(int)\n",
    "df_data_prep['clf_prob']     = clf.predict_proba( df_data_prep[train_vars] )[:,1]\n",
    "\n",
    "\n",
    "df_data_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exciting! let's plot on the 2D $\\xi$ planes the events which are classified as signal and background.\n",
    "Looks like some candidate events are selected!\n",
    "\n",
    "**TASK 2**\n",
    "\n",
    "Discussion: are these really signal events or generated by false positive rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_bkg_1 = None\n",
    "msk_bkg_2 = None\n",
    "msk_sig_1 = None\n",
    "msk_sig_2 = None\n",
    "if proton_selection == \"SingleRP\":\n",
    "    msk_bkg_1 = ( df_data_prep[ \"RPId1\" ] == 23 ) & ( df_data_prep['clf_category'] == 0 )\n",
    "    msk_bkg_2 = ( df_data_prep[ \"RPId1\" ] == 123 ) & ( df_data_prep['clf_category'] == 0 )\n",
    "    msk_sig_1 = ( df_data_prep[ \"RPId1\" ] == 23 ) & ( df_data_prep['clf_category'] == 1 )\n",
    "    msk_sig_2 = ( df_data_prep[ \"RPId1\" ] == 123 ) & ( df_data_prep['clf_category'] == 1 )\n",
    "elif proton_selection == \"MultiRP\":\n",
    "    msk_bkg_1 = ( df_data_prep[ \"Arm\" ] == 0 ) & ( df_data_prep['clf_category'] == 0 )\n",
    "    msk_bkg_2 = ( df_data_prep[ \"Arm\" ] == 1 ) & ( df_data_prep['clf_category'] == 0 )\n",
    "    msk_sig_1 = ( df_data_prep[ \"Arm\" ] == 0 ) & ( df_data_prep['clf_category'] == 1 )\n",
    "    msk_sig_2 = ( df_data_prep[ \"Arm\" ] == 1 ) & ( df_data_prep['clf_category'] == 1 )\n",
    "\n",
    "Plot2D('Xi','XiMuMuPlus', df_data_prep,df_data_prep,msk_sig_1,msk_bkg_1)\n",
    "Plot2D('Xi','XiMuMuMinus',df_data_prep,df_data_prep,msk_sig_2,msk_bkg_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the catgorization to plot the distributions of the variables for events which are classified as signal or as background.\n",
    "Maybe these distributions can give some insight into the characteristics of the events which are falling under the signal category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_vars:\n",
    "    showDist(x,df_data_prep,(df_data_prep['clf_category']==1),(df_data_prep['clf_category']==0),50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the events which have been classified as a signal against a background prediction,\n",
    "based on the event-mixed data which has been used for the training of the MVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareToBackgroundPrediction(var,data,msk_data,bkg,msk_bkg,bins=20,resample_factor=20):\n",
    "\n",
    "    fig, axes = plt.subplots( 1, 2, figsize=(20,10) )\n",
    "\n",
    "    #define the binning if only nbins were given\n",
    "    if isinstance(bins,int):\n",
    "        _,bins=np.histogram(df_data_prep[var],bins=bins)\n",
    "\n",
    "    counts={}\n",
    "    errors={}\n",
    "    for arm in [0,1]:\n",
    "      \n",
    "        counts[arm], bin_edges = np.histogram( data[var][msk_data[arm]], bins=bins )\n",
    "        errors[arm] = np.sqrt( counts[arm] )\n",
    "        bin_centres = ( bin_edges[:-1] + bin_edges[1:] ) / 2.\n",
    "        axes[arm].errorbar(bin_centres, counts[arm], yerr=errors[arm], fmt='o', label='Data')\n",
    "\n",
    "        weights = None\n",
    "        if resample_factor > 1:\n",
    "            weights = np.full_like( bkg[ \"Xi\" ][ msk_bkg[arm] ], ( 1./resample_factor ) )\n",
    "    \n",
    "        axes[arm].hist( bkg[ var ][ msk_bkg[arm] ], bins=bins, weights=weights, label='background' )\n",
    "        \n",
    "    #final tweak to display both y-axis with the same range\n",
    "    idx_ymax = np.argmax( np.concatenate( [counts[0], counts[1]] ) )\n",
    "    y_max = np.concatenate( [counts[0], counts[1]] )[idx_ymax] + 2*np.concatenate( [errors[0], errors[1]] )[idx_ymax]\n",
    "\n",
    "    for arm in [0,1]:    \n",
    "        axes[arm].set_ylim( top=y_max )\n",
    "        axes[arm].set_ylabel('Events')\n",
    "        axes[arm].set_xlabel(var)\n",
    "        axes[arm].grid()\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "msk_bkg_pred_1 = None\n",
    "msk_bkg_pred_2 = None\n",
    "if proton_selection == \"SingleRP\":\n",
    "    msk_bkg_pred_1 = ( df_bkg_prep[ \"RPId1\" ] == 23 ) & ( y_bkg_pred == 1 )\n",
    "    msk_bkg_pred_2 = ( df_bkg_prep[ \"RPId1\" ] == 123 ) & ( y_bkg_pred == 1 )\n",
    "elif proton_selection == \"MultiRP\":\n",
    "    msk_bkg_pred_1 = ( df_bkg_prep[ \"Arm\" ] == 0 ) & ( y_bkg_pred == 1 )\n",
    "    msk_bkg_pred_2 = ( df_bkg_prep[ \"Arm\" ] == 1 ) & ( y_bkg_pred == 1 )\n",
    "\n",
    "msk_data=[msk_sig_1,msk_sig_2]\n",
    "msk_bkg=[msk_bkg_pred_1,msk_bkg_pred_2]\n",
    "for var in train_vars:\n",
    "    compareToBackgroundPrediction(var,df_data_prep,msk_data,df_bkg_prep,msk_bkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3**\n",
    "\n",
    "Add the DeltaXi variable to the data and background data frames and plot it in the same style as before. \n",
    "What are your conclusions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your piece of code here\n",
    "\n",
    "#stuck? uncomment the following piece of code and run to see the solution\n",
    "#%load snippets/ClassificationTask3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 4**\n",
    "\n",
    "Once you are happy with the features, model and training, save your model so that it can be used for the statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
